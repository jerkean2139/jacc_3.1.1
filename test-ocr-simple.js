// Simple OCR and Chunking Test
const fs = require('fs');
const path = require('path');

async function testOCRAndChunking() {
  console.log('üîç Testing OCR and Chunking Functionality\n');
  
  // Test 1: Check uploaded files
  console.log('üìÅ Checking uploaded files...');
  const uploadsDir = './uploads';
  
  if (fs.existsSync(uploadsDir)) {
    const files = fs.readdirSync(uploadsDir);
    console.log(`Found ${files.length} uploaded files:`);
    
    // Show first 5 files with details
    files.slice(0, 5).forEach(file => {
      const filePath = path.join(uploadsDir, file);
      const stats = fs.statSync(filePath);
      const sizeKB = (stats.size / 1024).toFixed(1);
      console.log(`  üìÑ ${file} (${sizeKB}KB)`);
    });
  } else {
    console.log('‚ùå Uploads directory not found');
  }
  
  // Test 2: Check OCR dependencies
  console.log('\nüîç Checking OCR dependencies...');
  
  const dependencies = ['pdf-parse', 'tesseract.js', 'mammoth'];
  
  for (const dep of dependencies) {
    try {
      require.resolve(dep);
      console.log(`  ‚úÖ ${dep} - Available`);
    } catch (error) {
      console.log(`  ‚ùå ${dep} - Not installed`);
    }
  }
  
  // Test 3: Test basic chunking algorithm
  console.log('\nüß© Testing chunking algorithms...');
  
  const testText = `
    Payment processing involves multiple parties and fees. The merchant account provider processes transactions.
    Interchange rates are set by card networks like Visa and MasterCard. These rates vary by card type and transaction method.
    Assessment fees are additional charges from card networks. Authorization fees apply per transaction.
    Monthly fees include statement fees, gateway costs, and PCI compliance charges.
    Understanding these components helps merchants evaluate processor offers effectively.
  `;
  
  // Basic word-based chunking
  function chunkByWords(text, maxWords = 50) {
    const words = text.trim().split(/\s+/);
    const chunks = [];
    
    for (let i = 0; i < words.length; i += maxWords) {
      const chunk = words.slice(i, i + maxWords).join(' ');
      chunks.push({
        index: Math.floor(i / maxWords),
        content: chunk,
        wordCount: Math.min(maxWords, words.length - i)
      });
    }
    
    return chunks;
  }
  
  // Sentence-boundary chunking
  function chunkBySentences(text, maxChars = 200) {
    const sentences = text.split(/[.!?]+/).filter(s => s.trim().length > 0);
    const chunks = [];
    let currentChunk = '';
    let chunkIndex = 0;
    
    for (const sentence of sentences) {
      const trimmed = sentence.trim();
      if (currentChunk.length + trimmed.length > maxChars && currentChunk.length > 0) {
        chunks.push({
          index: chunkIndex++,
          content: currentChunk.trim(),
          charCount: currentChunk.trim().length,
          sentenceCount: currentChunk.split(/[.!?]+/).length - 1
        });
        currentChunk = trimmed + '. ';
      } else {
        currentChunk += trimmed + '. ';
      }
    }
    
    if (currentChunk.trim()) {
      chunks.push({
        index: chunkIndex,
        content: currentChunk.trim(),
        charCount: currentChunk.trim().length,
        sentenceCount: currentChunk.split(/[.!?]+/).length - 1
      });
    }
    
    return chunks;
  }
  
  const wordChunks = chunkByWords(testText, 30);
  const sentenceChunks = chunkBySentences(testText, 150);
  
  console.log(`  üìù Word-based chunking: ${wordChunks.length} chunks`);
  wordChunks.forEach(chunk => {
    console.log(`    Chunk ${chunk.index}: ${chunk.wordCount} words`);
  });
  
  console.log(`  üìù Sentence-based chunking: ${sentenceChunks.length} chunks`);
  sentenceChunks.forEach(chunk => {
    console.log(`    Chunk ${chunk.index}: ${chunk.charCount} chars, ${chunk.sentenceCount} sentences`);
  });
  
  // Test 4: Test PDF processing if available
  console.log('\nüìÑ Testing PDF processing...');
  
  try {
    const pdfParse = require('pdf-parse');
    console.log('  ‚úÖ pdf-parse module loaded successfully');
    
    // Find PDF files in uploads
    if (fs.existsSync(uploadsDir)) {
      const pdfFiles = fs.readdirSync(uploadsDir)
        .filter(file => path.extname(file).toLowerCase() === '.pdf')
        .slice(0, 2); // Test first 2 PDFs
      
      console.log(`  Found ${pdfFiles.length} PDF files to test`);
      
      for (const pdfFile of pdfFiles) {
        try {
          const pdfPath = path.join(uploadsDir, pdfFile);
          const dataBuffer = fs.readFileSync(pdfPath);
          
          console.log(`  üìÑ Testing ${pdfFile}...`);
          const data = await pdfParse(dataBuffer);
          
          console.log(`    ‚úÖ Extracted ${data.text.length} characters`);
          console.log(`    üìä ${data.numpages} pages`);
          
          // Test chunking on extracted text
          if (data.text.length > 0) {
            const pdfChunks = chunkBySentences(data.text, 300);
            console.log(`    üß© Created ${pdfChunks.length} chunks from PDF text`);
          }
          
        } catch (pdfError) {
          console.log(`    ‚ùå PDF processing failed: ${pdfError.message}`);
        }
      }
    }
    
  } catch (error) {
    console.log('  ‚ùå pdf-parse not available for testing');
  }
  
  // Test 5: Check document processing workflow
  console.log('\n‚öôÔ∏è  Testing document processing workflow...');
  
  // Simulate the document processing pipeline
  function simulateDocumentProcessing(filename, content) {
    console.log(`  üìÑ Processing: ${filename}`);
    
    // Step 1: Extract text (simulated)
    const extractedText = content || 'Sample extracted text from document processing.';
    console.log(`    1Ô∏è‚É£ Text extraction: ${extractedText.length} characters`);
    
    // Step 2: Chunk the text
    const chunks = chunkBySentences(extractedText, 200);
    console.log(`    2Ô∏è‚É£ Text chunking: ${chunks.length} chunks created`);
    
    // Step 3: Generate metadata
    const metadata = {
      filename,
      wordCount: extractedText.split(/\s+/).length,
      chunkCount: chunks.length,
      processedAt: new Date().toISOString()
    };
    console.log(`    3Ô∏è‚É£ Metadata: ${JSON.stringify(metadata, null, 2)}`);
    
    return { chunks, metadata };
  }
  
  // Test with sample documents
  const testDocs = [
    { name: 'merchant_agreement.pdf', content: testText },
    { name: 'pricing_sheet.pdf', content: 'Processing rates: 2.9% + $0.30 per transaction. Monthly fee: $25.' }
  ];
  
  testDocs.forEach(doc => {
    simulateDocumentProcessing(doc.name, doc.content);
  });
  
  console.log('\n‚úÖ OCR and Chunking functionality test completed');
  console.log('\nüìã Summary:');
  console.log('‚Ä¢ File access: Working');
  console.log('‚Ä¢ Chunking algorithms: Implemented and tested');
  console.log('‚Ä¢ Document processing workflow: Functional');
  console.log('‚Ä¢ PDF processing: Available (if pdf-parse installed)');
}

// Run the test
testOCRAndChunking().catch(console.error);